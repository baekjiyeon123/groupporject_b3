{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f218a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from xgboost import plot_importance\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb\n",
    "from lightgbm import plot_importance\n",
    "from lightgbm import plot_importance\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "import scipy.stats as stats \n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import qqplot, add_constant\n",
    "from statsmodels.api import Logit\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "import graphviz\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans, DBSCAN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "matplotlib.rc('font', family = 'NanumBarunGothic')\n",
    "matplotlib.rc('axes', unicode_minus = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcdb42b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_csv(\"/home/piai/merged_with_2.csv\", encoding = 'euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35a3358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14760, 57)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16376019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['Ox_Chamber'] = df_merged['Ox_Chamber'].astype(str)\n",
    "df_merged['Lot_Num'] = df_merged['Lot_Num'].astype(str)\n",
    "df_merged['Wafer_Num'] = df_merged['Wafer_Num'].astype(str)\n",
    "\n",
    "df_merged['photo_soft_Chamber'] = df_merged['photo_soft_Chamber'].astype(str)\n",
    "\n",
    "df_merged['lithography_Chamber'] = df_merged['lithography_Chamber'].astype(str)\n",
    "df_merged['Wavelength'] = df_merged['Wavelength'].astype(str)\n",
    "\n",
    "df_merged['Etching_Chamber'] = df_merged['Etching_Chamber'].astype(str)\n",
    "\n",
    "# Flux480s, Flux840s, RTA_Temp 이산형 확인 .astype('category')\n",
    "df_merged['Chamber_Num'] = df_merged['Chamber_Num'].astype(str)\n",
    "\n",
    "df_merged['wafer_defect'] = df_merged['wafer_defect'].astype('category')\n",
    "df_merged['Line_CD_state'] = df_merged['Line_CD_state'].astype('category')\n",
    "df_merged['thickness_state'] = df_merged['thickness_state'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fb6cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14760 entries, 0 to 14759\n",
      "Data columns (total 57 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   Ox_Chamber            14760 non-null  object  \n",
      " 1   type                  14760 non-null  object  \n",
      " 2   Temp_OXid             14760 non-null  float64 \n",
      " 3   Vapor                 14760 non-null  object  \n",
      " 4   ppm                   14760 non-null  float64 \n",
      " 5   Pressure              14760 non-null  float64 \n",
      " 6   Oxid_time             14760 non-null  int64   \n",
      " 7   thickness             14760 non-null  float64 \n",
      " 8   Lot_Num               14760 non-null  object  \n",
      " 9   Wafer_Num             14760 non-null  object  \n",
      " 10  photo_soft_Chamber    14760 non-null  object  \n",
      " 11  resist_target         14760 non-null  float64 \n",
      " 12  N2_HMDS               14760 non-null  float64 \n",
      " 13  pressure_HMDS         14760 non-null  float64 \n",
      " 14  temp_HMDS             14760 non-null  float64 \n",
      " 15  temp_HMDS_bake        14760 non-null  float64 \n",
      " 16  time_HMDS_bake        14760 non-null  float64 \n",
      " 17  spin1                 14760 non-null  float64 \n",
      " 18  spin2                 14760 non-null  float64 \n",
      " 19  spin3                 14760 non-null  float64 \n",
      " 20  photoresist_bake      14760 non-null  float64 \n",
      " 21  temp_softbake         14760 non-null  float64 \n",
      " 22  time_softbake         14760 non-null  float64 \n",
      " 23  lithography_Chamber   14760 non-null  object  \n",
      " 24  Line_CD               14760 non-null  float64 \n",
      " 25  UV_type               14760 non-null  object  \n",
      " 26  Wavelength            14760 non-null  object  \n",
      " 27  Resolution            14760 non-null  float64 \n",
      " 28  Energy_Exposure       14760 non-null  float64 \n",
      " 29  Etching_Chamber       14760 non-null  object  \n",
      " 30  Thin F4               14760 non-null  float64 \n",
      " 31  Thin F3               14760 non-null  float64 \n",
      " 32  Thin F2               14760 non-null  float64 \n",
      " 33  Thin F1               14760 non-null  float64 \n",
      " 34  Temp_Etching          14760 non-null  float64 \n",
      " 35  Source_Power          14760 non-null  float64 \n",
      " 36  Selectivity           14760 non-null  float64 \n",
      " 37  Chamber_Num           14760 non-null  object  \n",
      " 38  Flux60s               14760 non-null  float64 \n",
      " 39  Flux90s               14760 non-null  float64 \n",
      " 40  Flux160s              14760 non-null  float64 \n",
      " 41  Flux480s              14760 non-null  float64 \n",
      " 42  input_Energy          14760 non-null  float64 \n",
      " 43  Temp_implantation     14760 non-null  float64 \n",
      " 44  Furance_Temp          14760 non-null  float64 \n",
      " 45  RTA_Temp              14760 non-null  int64   \n",
      " 46  Target                14760 non-null  int64   \n",
      " 47  Error_message         14760 non-null  object  \n",
      " 48  merged_Chamber        14760 non-null  int64   \n",
      " 49  path                  14760 non-null  int64   \n",
      " 50  wafer_defect          14760 non-null  category\n",
      " 51  Month                 14760 non-null  int64   \n",
      " 52  IsWeekend             14760 non-null  int64   \n",
      " 53  Line_CD_state         14760 non-null  category\n",
      " 54  thickness_state       14760 non-null  category\n",
      " 55  Defective_Rate_chip   14760 non-null  float64 \n",
      " 56  Defective_Rate_wafer  14760 non-null  float64 \n",
      "dtypes: category(3), float64(35), int64(7), object(12)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa324bca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # 숫자형 피처만 필터링\n",
    "# numerical_features = df_merged.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# anova_results = {}\n",
    "# for feature in numerical_features:\n",
    "#     feature_values = df_merged[feature]\n",
    "    \n",
    "#     p_values = []\n",
    "#     for other_feature in numerical_features:\n",
    "#         if other_feature != feature:\n",
    "#             other_values = df_merged[other_feature]\n",
    "#             try:\n",
    "#                 # ANOVA 수행\n",
    "#                 f_stat, p_value = f_oneway(feature_values, other_values)\n",
    "#                 p_values.append((min(feature, other_feature), max(feature, other_feature), p_value))\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing feature {feature} with {other_feature}: {e}\")\n",
    "#                 p_values.append((min(feature, other_feature), max(feature, other_feature), None))\n",
    "    \n",
    "#     # 피처별 ANOVA 결과를 데이터프레임에 추가\n",
    "#     anova_results[feature] = p_values\n",
    "\n",
    "# # 유의하지 않은 결과만 필터링 (p-value > 0.05)\n",
    "# non_significant_results = []\n",
    "# for feature, results in anova_results.items():\n",
    "#     for f1, f2, p_value in results:\n",
    "#         if p_value is not None and p_value > 0.05:\n",
    "#             non_significant_results.append((f1, f2, p_value))\n",
    "\n",
    "# # 중복 제거 (정렬된 피처 쌍에 대한 중복 제거)\n",
    "# non_significant_results = list(set(non_significant_results))\n",
    "\n",
    "# # 결과를 p-value 기준으로 오름차순 정렬\n",
    "# non_significant_results_sorted = sorted(non_significant_results, key=lambda x: x[2])\n",
    "\n",
    "# # 결과 데이터프레임 생성 및 출력 - Non-significant Results (p-value > 0.05):\n",
    "#   Feature 1          Feature 2   p-value\n",
    "# 0    Target  Temp_implantation  0.255976\n",
    "# non_significant_df = pd.DataFrame(non_significant_results_sorted, columns=['Feature 1', 'Feature 2', 'p-value'])\n",
    "# print(\"\\nANOVA - Non-significant Results (p-value > 0.05):\")\n",
    "# print(non_significant_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf72059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 숫자형 피처만 필터링\n",
    "# numerical_features = df_merged.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# t_test_results = {}\n",
    "# for feature in numerical_features:\n",
    "#     feature_values = df_merged[feature]\n",
    "    \n",
    "#     p_values = []\n",
    "#     for other_feature in numerical_features:\n",
    "#         if other_feature != feature:\n",
    "#             other_values = df_merged[other_feature]\n",
    "#             try:\n",
    "#                 # t-검정 수행\n",
    "#                 t_stat, p_value = ttest_ind(feature_values, other_values, nan_policy='omit')\n",
    "#                 p_values.append((min(feature, other_feature), max(feature, other_feature), p_value))\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing feature {feature} with {other_feature}: {e}\")\n",
    "#                 p_values.append((min(feature, other_feature), max(feature, other_feature), None))\n",
    "    \n",
    "#     # 피처별 t-검정 결과를 데이터프레임에 추가\n",
    "#     t_test_results[feature] = p_values\n",
    "\n",
    "# # 유의하지 않은 결과만 필터링 (p-value > 0.05)\n",
    "# non_significant_results = []\n",
    "# for feature, results in t_test_results.items():\n",
    "#     for f1, f2, p_value in results:\n",
    "#         if p_value is not None and p_value > 0.05:\n",
    "#             non_significant_results.append((f1, f2, p_value))\n",
    "\n",
    "# # 중복 제거 (정렬된 피처 쌍에 대한 중복 제거)\n",
    "# non_significant_results = list(set(non_significant_results))\n",
    "\n",
    "# # 결과를 p-value 기준으로 오름차순 정렬\n",
    "# non_significant_results_sorted = sorted(non_significant_results, key=lambda x: x[2])\n",
    "\n",
    "# # 결과 데이터프레임 생성 및 출력\n",
    "# non_significant_df = pd.DataFrame(non_significant_results_sorted, columns=['Feature 1', 'Feature 2', 'p-value'])\n",
    "# print(\"\\nT-test - Non-significant Results (p-value > 0.05) sorted by p-value:\")\n",
    "# print(non_significant_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a238bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chi2_statistic_and_pvalue(confusion_matrix):\n",
    "#     chi2_stat, p_value, _, _ = chi2_contingency(confusion_matrix, correction=False)\n",
    "#     return chi2_stat, p_value\n",
    "\n",
    "# # 범주형 피처만 필터링\n",
    "# categorical_features = df_merged.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# chi2_results = []\n",
    "# for feature in categorical_features:\n",
    "#     feature_values = df_merged[feature].dropna()\n",
    "    \n",
    "#     for other_feature in categorical_features:\n",
    "#         if other_feature != feature:\n",
    "#             other_values = df_merged[other_feature].dropna()\n",
    "            \n",
    "#             # 교차표 생성\n",
    "#             contingency_table = pd.crosstab(feature_values, other_values)\n",
    "            \n",
    "#             # Ensure the table has more than one row and column\n",
    "#             if contingency_table.shape[0] > 1 and contingency_table.shape[1] > 1:\n",
    "#                 try:\n",
    "#                     # 카이제곱 통계량과 p-value 계산\n",
    "#                     chi2_stat, p_value = chi2_statistic_and_pvalue(contingency_table)\n",
    "#                     chi2_results.append((feature, other_feature, chi2_stat, p_value))\n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing feature {feature} with {other_feature}: {e}\")\n",
    "#                     chi2_results.append((feature, other_feature, None, None))\n",
    "#             else:\n",
    "#                 chi2_results.append((feature, other_feature, None, None))\n",
    "\n",
    "# # 결과를 데이터프레임으로 변환\n",
    "# chi2_df = pd.DataFrame(chi2_results, columns=['Feature 1', 'Feature 2', 'Chi-Square Statistic', 'p-value'])\n",
    "\n",
    "# # Feature Pair를 기준으로 중복 제거\n",
    "# chi2_df['Feature Pair'] = chi2_df.apply(lambda x: tuple(sorted([x['Feature 1'], x['Feature 2']])), axis=1)\n",
    "# chi2_df = chi2_df.drop_duplicates(subset=['Feature Pair'])\n",
    "\n",
    "# # p-value가 높은 결과만 필터링 (예: p-value > 0.05)\n",
    "# chi2_df_filtered = chi2_df[chi2_df['p-value'] > 0.05]\n",
    "\n",
    "# # p-value 기준으로 오름차순 정렬\n",
    "# chi2_df_sorted = chi2_df_filtered.sort_values(by='p-value')\n",
    "\n",
    "# # 결과 출력\n",
    "# print(\"\\nChi-Square Statistic and p-value - Results with high p-values (sorted by p-value):\")\n",
    "# print(chi2_df_sorted[['Feature 1', 'Feature 2', 'Chi-Square Statistic', 'p-value']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f07f700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop(columns=['ppm', 'Defective_Rate_chip', 'wafer_defect'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eb2e3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14760 entries, 0 to 14759\n",
      "Data columns (total 54 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   Ox_Chamber            14760 non-null  object  \n",
      " 1   type                  14760 non-null  object  \n",
      " 2   Temp_OXid             14760 non-null  float64 \n",
      " 3   Vapor                 14760 non-null  object  \n",
      " 4   Pressure              14760 non-null  float64 \n",
      " 5   Oxid_time             14760 non-null  int64   \n",
      " 6   thickness             14760 non-null  float64 \n",
      " 7   Lot_Num               14760 non-null  object  \n",
      " 8   Wafer_Num             14760 non-null  object  \n",
      " 9   photo_soft_Chamber    14760 non-null  object  \n",
      " 10  resist_target         14760 non-null  float64 \n",
      " 11  N2_HMDS               14760 non-null  float64 \n",
      " 12  pressure_HMDS         14760 non-null  float64 \n",
      " 13  temp_HMDS             14760 non-null  float64 \n",
      " 14  temp_HMDS_bake        14760 non-null  float64 \n",
      " 15  time_HMDS_bake        14760 non-null  float64 \n",
      " 16  spin1                 14760 non-null  float64 \n",
      " 17  spin2                 14760 non-null  float64 \n",
      " 18  spin3                 14760 non-null  float64 \n",
      " 19  photoresist_bake      14760 non-null  float64 \n",
      " 20  temp_softbake         14760 non-null  float64 \n",
      " 21  time_softbake         14760 non-null  float64 \n",
      " 22  lithography_Chamber   14760 non-null  object  \n",
      " 23  Line_CD               14760 non-null  float64 \n",
      " 24  UV_type               14760 non-null  object  \n",
      " 25  Wavelength            14760 non-null  object  \n",
      " 26  Resolution            14760 non-null  float64 \n",
      " 27  Energy_Exposure       14760 non-null  float64 \n",
      " 28  Etching_Chamber       14760 non-null  object  \n",
      " 29  Thin F4               14760 non-null  float64 \n",
      " 30  Thin F3               14760 non-null  float64 \n",
      " 31  Thin F2               14760 non-null  float64 \n",
      " 32  Thin F1               14760 non-null  float64 \n",
      " 33  Temp_Etching          14760 non-null  float64 \n",
      " 34  Source_Power          14760 non-null  float64 \n",
      " 35  Selectivity           14760 non-null  float64 \n",
      " 36  Chamber_Num           14760 non-null  object  \n",
      " 37  Flux60s               14760 non-null  float64 \n",
      " 38  Flux90s               14760 non-null  float64 \n",
      " 39  Flux160s              14760 non-null  float64 \n",
      " 40  Flux480s              14760 non-null  float64 \n",
      " 41  input_Energy          14760 non-null  float64 \n",
      " 42  Temp_implantation     14760 non-null  float64 \n",
      " 43  Furance_Temp          14760 non-null  float64 \n",
      " 44  RTA_Temp              14760 non-null  int64   \n",
      " 45  Target                14760 non-null  int64   \n",
      " 46  Error_message         14760 non-null  object  \n",
      " 47  merged_Chamber        14760 non-null  int64   \n",
      " 48  path                  14760 non-null  int64   \n",
      " 49  Month                 14760 non-null  int64   \n",
      " 50  IsWeekend             14760 non-null  int64   \n",
      " 51  Line_CD_state         14760 non-null  category\n",
      " 52  thickness_state       14760 non-null  category\n",
      " 53  Defective_Rate_wafer  14760 non-null  float64 \n",
      "dtypes: category(2), float64(33), int64(7), object(12)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "498a550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 정의\n",
    "df_char = df_merged.select_dtypes(include=\"object\")\n",
    "df_numeric = df_merged.select_dtypes(exclude=\"object\")\n",
    "\n",
    "# 숫자형 데이터 표준화\n",
    "scaler = StandardScaler()\n",
    "np_numeric_scaled = scaler.fit_transform(df_numeric)\n",
    "df_numeric_scaled = pd.DataFrame(np_numeric_scaled, columns=df_numeric.columns, index=df_numeric.index)\n",
    "\n",
    "# 범주형 데이터 원-핫 인코딩\n",
    "df_encoded = pd.get_dummies(df_char, drop_first=True)\n",
    "\n",
    "# 최종 데이터프레임 생성\n",
    "df_final = df_numeric_scaled.join(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6027c92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size : (10332, 149)\n",
      "Test data size : (4428, 149)\n",
      "X_train data size : (10332, 148)\n",
      "y_train data size : (10332,)\n",
      "X_test data size : (4428, 148)\n",
      "y_test data size : (4428,)\n"
     ]
    }
   ],
   "source": [
    "# 타겟 변수와 설명 변수 정의\n",
    "df_final['Target'] = df_merged['Target']  # 타겟 변수 추가\n",
    "\n",
    "# 데이터 분할\n",
    "df_train, df_test = train_test_split(df_final, test_size=0.3, random_state=1234)\n",
    "\n",
    "print('Train data size : {}'.format(df_train.shape)) \n",
    "print('Test data size : {}'.format(df_test.shape))\n",
    "\n",
    "# 타겟 변수와 설명 변수 정의\n",
    "X_train = df_train.drop(columns='Target')\n",
    "y_train = df_train['Target']\n",
    "X_test = df_test.drop(columns='Target')\n",
    "y_test = df_test['Target']\n",
    "\n",
    "print('X_train data size : {}'.format(X_train.shape)) \n",
    "print('y_train data size : {}'.format(y_train.shape))\n",
    "print('X_test data size : {}'.format(X_test.shape)) \n",
    "print('y_test data size : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4efbbbfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거된 변수: Wafer_Num_24 (p-value: 0.9753)\n",
      "제거된 변수: N2_HMDS (p-value: 0.9522)\n",
      "제거된 변수: Month (p-value: 0.8997)\n",
      "제거된 변수: Wafer_Num_4 (p-value: 0.8907)\n",
      "제거된 변수: Wafer_Num_12 (p-value: 0.8630)\n",
      "제거된 변수: Error_message_[['Random']] (p-value: 0.8068)\n",
      "제거된 변수: Lot_Num_6 (p-value: 0.7808)\n",
      "제거된 변수: Wafer_Num_27 (p-value: 0.7792)\n",
      "제거된 변수: Wafer_Num_25 (p-value: 0.7999)\n",
      "제거된 변수: Wafer_Num_3 (p-value: 0.7886)\n",
      "제거된 변수: Wafer_Num_18 (p-value: 0.8172)\n",
      "제거된 변수: time_HMDS_bake (p-value: 0.7575)\n",
      "제거된 변수: time_softbake (p-value: 0.7528)\n",
      "제거된 변수: Wafer_Num_2 (p-value: 0.6530)\n",
      "제거된 변수: Flux90s (p-value: 0.6287)\n",
      "제거된 변수: Wafer_Num_26 (p-value: 0.6349)\n",
      "제거된 변수: Wafer_Num_6 (p-value: 0.6515)\n",
      "제거된 변수: IsWeekend (p-value: 0.5719)\n",
      "제거된 변수: Lot_Num_4 (p-value: 0.5471)\n",
      "제거된 변수: Lot_Num_15 (p-value: 0.6234)\n",
      "제거된 변수: lithography_Chamber_2 (p-value: 0.5159)\n",
      "제거된 변수: Wafer_Num_54 (p-value: 0.4867)\n",
      "제거된 변수: Wafer_Num_21 (p-value: 0.4749)\n",
      "제거된 변수: Wafer_Num_22 (p-value: 0.3777)\n",
      "제거된 변수: Wafer_Num_50 (p-value: 0.3602)\n",
      "제거된 변수: path (p-value: 0.9659)\n",
      "제거된 변수: Ox_Chamber_2 (p-value: 0.9908)\n",
      "제거된 변수: Chamber_Num_2 (p-value: 0.8259)\n",
      "제거된 변수: Etching_Chamber_2 (p-value: 0.8259)\n",
      "제거된 변수: photo_soft_Chamber_3 (p-value: 0.7538)\n",
      "제거된 변수: Ox_Chamber_3 (p-value: 0.7064)\n",
      "제거된 변수: Wafer_Num_47 (p-value: 0.3234)\n",
      "제거된 변수: Wafer_Num_11 (p-value: 0.2395)\n",
      "제거된 변수: spin1 (p-value: 0.2377)\n",
      "제거된 변수: Source_Power (p-value: 0.2312)\n",
      "제거된 변수: Selectivity (p-value: 0.2059)\n",
      "제거된 변수: photo_soft_Chamber_2 (p-value: 0.2024)\n",
      "제거된 변수: Defective_Rate_wafer (p-value: 0.2239)\n",
      "제거된 변수: Lot_Num_16 (p-value: 0.2659)\n",
      "제거된 변수: Flux160s (p-value: 0.1842)\n",
      "제거된 변수: temp_HMDS (p-value: 0.1404)\n",
      "제거된 변수: Wafer_Num_29 (p-value: 0.1335)\n",
      "제거된 변수: lithography_Chamber_3 (p-value: 0.1798)\n",
      "제거된 변수: Wafer_Num_35 (p-value: 0.1836)\n",
      "제거된 변수: Wafer_Num_28 (p-value: 0.1909)\n",
      "제거된 변수: Wafer_Num_36 (p-value: 0.1906)\n",
      "제거된 변수: Wafer_Num_10 (p-value: 0.1597)\n",
      "제거된 변수: RTA_Temp (p-value: 0.1390)\n",
      "제거된 변수: Wafer_Num_13 (p-value: 0.1325)\n",
      "제거된 변수: Pressure (p-value: 0.1194)\n",
      "제거된 변수: Lot_Num_14 (p-value: 0.0984)\n",
      "제거된 변수: Lot_Num_11 (p-value: 0.1175)\n",
      "제거된 변수: Lot_Num_12 (p-value: 0.1504)\n",
      "제거된 변수: photoresist_bake (p-value: 0.1160)\n",
      "제거된 변수: Lot_Num_5 (p-value: 0.1138)\n",
      "제거된 변수: Oxid_time (p-value: 0.1130)\n",
      "제거된 변수: merged_Chamber (p-value: 0.1072)\n",
      "제거된 변수: Error_message_[['Near-full']] (p-value: 0.1053)\n",
      "제거된 변수: Flux480s (p-value: 0.1006)\n",
      "제거된 변수: Error_message_[['Scratch']] (p-value: 0.0969)\n",
      "제거된 변수: Wafer_Num_49 (p-value: 0.0793)\n",
      "제거된 변수: Wafer_Num_30 (p-value: 0.0711)\n",
      "제거된 변수: Wafer_Num_48 (p-value: 0.0978)\n",
      "제거된 변수: Chamber_Num_3 (p-value: 0.1286)\n",
      "제거된 변수: Etching_Chamber_3 (p-value: 0.1286)\n",
      "제거된 변수: Wafer_Num_17 (p-value: 0.0555)\n",
      "제거된 변수: Wafer_Num_33 (p-value: 0.0544)\n",
      "제거된 변수: Wafer_Num_52 (p-value: 0.0607)\n",
      "제거된 변수: Wafer_Num_19 (p-value: 0.0685)\n",
      "제거된 변수: input_Energy (p-value: 0.0537)\n",
      "최종 모델 요약 (후진 제거법 적용 후):\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Target   R-squared:                       0.758\n",
      "Model:                            OLS   Adj. R-squared:                  0.757\n",
      "Method:                 Least Squares   F-statistic:                     429.0\n",
      "Date:                Mon, 19 Aug 2024   Prob (F-statistic):               0.00\n",
      "Time:                        08:21:23   Log-Likelihood:                -50095.\n",
      "No. Observations:               10332   AIC:                         1.003e+05\n",
      "Df Residuals:                   10256   BIC:                         1.009e+05\n",
      "Df Model:                          75                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================================\n",
      "                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------\n",
      "const                            92.2801      1.381     66.808      0.000      89.573      94.988\n",
      "Temp_OXid                         1.6296      0.684      2.382      0.017       0.288       2.971\n",
      "thickness                        -1.0183      0.493     -2.064      0.039      -1.985      -0.051\n",
      "resist_target                     1.3674      0.340      4.022      0.000       0.701       2.034\n",
      "pressure_HMDS                    -1.1821      0.308     -3.836      0.000      -1.786      -0.578\n",
      "temp_HMDS_bake                   -2.3924      0.391     -6.117      0.000      -3.159      -1.626\n",
      "spin2                            -0.7884      0.373     -2.113      0.035      -1.520      -0.057\n",
      "spin3                            -2.2283      0.419     -5.321      0.000      -3.049      -1.407\n",
      "temp_softbake                    -2.3768      0.397     -5.994      0.000      -3.154      -1.599\n",
      "Line_CD                           2.6142      0.410      6.371      0.000       1.810       3.419\n",
      "Resolution                        1.3081      0.457      2.865      0.004       0.413       2.203\n",
      "Energy_Exposure                   0.9696      0.426      2.274      0.023       0.134       1.805\n",
      "Thin F4                          18.9926      0.416     45.611      0.000      18.176      19.809\n",
      "Thin F3                          11.9562      0.340     35.177      0.000      11.290      12.622\n",
      "Thin F2                          18.7859      0.382     49.180      0.000      18.037      19.535\n",
      "Thin F1                          -2.4280      0.329     -7.380      0.000      -3.073      -1.783\n",
      "Temp_Etching                      1.5112      0.364      4.150      0.000       0.797       2.225\n",
      "Flux60s                          -0.9702      0.316     -3.066      0.002      -1.591      -0.350\n",
      "Temp_implantation                 0.9873      0.412      2.397      0.017       0.180       1.795\n",
      "Furance_Temp                      1.0138      0.448      2.264      0.024       0.136       1.891\n",
      "Line_CD_state                     0.9435      0.341      2.763      0.006       0.274       1.613\n",
      "thickness_state                  -1.0208      0.437     -2.336      0.020      -1.877      -0.164\n",
      "type_wet                         43.7881      0.822     53.242      0.000      42.176      45.400\n",
      "Vapor_O2                         48.4920      0.799     60.660      0.000      46.925      50.059\n",
      "Lot_Num_10                       -7.0257      1.913     -3.673      0.000     -10.775      -3.276\n",
      "Lot_Num_13                        6.7984      1.825      3.725      0.000       3.221      10.376\n",
      "Lot_Num_17                       -8.5177      1.841     -4.627      0.000     -12.126      -4.909\n",
      "Lot_Num_18                        6.9351      2.464      2.815      0.005       2.106      11.764\n",
      "Lot_Num_19                       22.0188      2.393      9.203      0.000      17.329      26.709\n",
      "Lot_Num_2                         6.2349      1.819      3.428      0.001       2.670       9.800\n",
      "Lot_Num_20                       40.6449      2.495     16.289      0.000      35.754      45.536\n",
      "Lot_Num_21                       44.8400      2.509     17.871      0.000      39.922      49.758\n",
      "Lot_Num_22                       28.5502      2.434     11.730      0.000      23.779      33.321\n",
      "Lot_Num_23                       34.8009      2.350     14.806      0.000      30.194      39.408\n",
      "Lot_Num_24                       25.7981      2.291     11.262      0.000      21.308      30.288\n",
      "Lot_Num_25                       34.9431      2.459     14.212      0.000      30.123      39.763\n",
      "Lot_Num_26                       24.7104      2.458     10.053      0.000      19.892      29.529\n",
      "Lot_Num_27                       11.8452      2.443      4.848      0.000       7.056      16.635\n",
      "Lot_Num_28                       22.4472      2.533      8.862      0.000      17.482      27.412\n",
      "Lot_Num_29                       18.9468      2.485      7.625      0.000      14.076      23.818\n",
      "Lot_Num_3                        10.3072      1.858      5.549      0.000       6.666      13.948\n",
      "Lot_Num_30                       14.1182      2.558      5.519      0.000       9.104      19.132\n",
      "Lot_Num_31                       26.0638      2.514     10.369      0.000      21.136      30.991\n",
      "Lot_Num_32                       26.3669      3.197      8.247      0.000      20.100      32.634\n",
      "Lot_Num_7                         4.9643      1.846      2.689      0.007       1.345       8.583\n",
      "Lot_Num_8                         7.1445      1.887      3.786      0.000       3.445      10.844\n",
      "Lot_Num_9                         6.7520      1.853      3.644      0.000       3.120      10.384\n",
      "Wafer_Num_14                      6.7590      2.239      3.019      0.003       2.370      11.148\n",
      "Wafer_Num_15                      5.5430      2.294      2.416      0.016       1.046      10.040\n",
      "Wafer_Num_16                     -8.2281      2.324     -3.541      0.000     -12.783      -3.673\n",
      "Wafer_Num_20                      7.4100      2.272      3.261      0.001       2.956      11.865\n",
      "Wafer_Num_23                      6.7907      2.292      2.963      0.003       2.298      11.283\n",
      "Wafer_Num_31                     -5.0688      2.282     -2.221      0.026      -9.543      -0.595\n",
      "Wafer_Num_32                     -5.5627      2.236     -2.488      0.013      -9.945      -1.180\n",
      "Wafer_Num_34                     14.2429      2.241      6.354      0.000       9.849      18.636\n",
      "Wafer_Num_37                    -11.3519      2.209     -5.138      0.000     -15.683      -7.021\n",
      "Wafer_Num_38                    -10.9546      2.259     -4.850      0.000     -15.382      -6.527\n",
      "Wafer_Num_39                     -6.9697      2.400     -2.904      0.004     -11.674      -2.265\n",
      "Wafer_Num_40                     -6.0157      2.205     -2.728      0.006     -10.338      -1.693\n",
      "Wafer_Num_41                     -6.9456      2.279     -3.048      0.002     -11.413      -2.478\n",
      "Wafer_Num_42                     -7.5426      2.335     -3.230      0.001     -12.120      -2.966\n",
      "Wafer_Num_43                     -9.5476      2.320     -4.115      0.000     -14.095      -5.000\n",
      "Wafer_Num_44                     -7.2076      2.351     -3.066      0.002     -11.816      -2.599\n",
      "Wafer_Num_45                     -4.9166      2.309     -2.130      0.033      -9.442      -0.391\n",
      "Wafer_Num_46                    -15.9806      2.317     -6.898      0.000     -20.522     -11.440\n",
      "Wafer_Num_5                       5.6584      2.279      2.483      0.013       1.191      10.125\n",
      "Wafer_Num_51                     -6.7564      2.292     -2.947      0.003     -11.250      -2.263\n",
      "Wafer_Num_53                     -7.0899      2.390     -2.967      0.003     -11.774      -2.405\n",
      "Wafer_Num_7                      12.7117      2.277      5.583      0.000       8.248      17.175\n",
      "Wafer_Num_8                       5.2317      2.296      2.278      0.023       0.730       9.733\n",
      "Wafer_Num_9                       8.0396      2.335      3.443      0.001       3.462      12.617\n",
      "UV_type_H                        17.9525      0.431     41.644      0.000      17.107      18.798\n",
      "UV_type_I                        36.3468      0.813     44.699      0.000      34.753      37.941\n",
      "Wavelength_405                   17.9525      0.431     41.644      0.000      17.107      18.798\n",
      "Wavelength_436                   37.9808      0.767     49.532      0.000      36.478      39.484\n",
      "Error_message_[['Edge-Loc']]     13.0280      2.849      4.572      0.000       7.443      18.613\n",
      "Error_message_[['Edge-Ring']]   -33.9944      6.454     -5.267      0.000     -46.646     -21.343\n",
      "Error_message_[['Loc']]          19.9380      3.327      5.993      0.000      13.416      26.460\n",
      "Error_message_none              -92.3070      2.510    -36.772      0.000     -97.228     -87.386\n",
      "==============================================================================\n",
      "Omnibus:                     1079.232   Durbin-Watson:                   1.975\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6615.945\n",
      "Skew:                           0.307   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.872   Cond. No.                     1.25e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 2.3e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "# 후진 제거법 구현\n",
    "def backward_elimination(X, y, significance_level=0.05):\n",
    "    variables = X.columns.tolist()\n",
    "    removed_variables = []\n",
    "    \n",
    "    while True:\n",
    "        X_with_const = sm.add_constant(X[variables])\n",
    "        model = sm.OLS(y, X_with_const).fit()\n",
    "        \n",
    "        # p-value가 가장 높은 변수 찾기\n",
    "        p_values = model.pvalues\n",
    "        max_p_value = p_values.max()\n",
    "        \n",
    "        if max_p_value > significance_level:\n",
    "            # p-value가 가장 높은 변수 제거\n",
    "            excluded_variable = p_values.idxmax()\n",
    "            if excluded_variable == 'const':\n",
    "                break\n",
    "            variables.remove(excluded_variable)\n",
    "            removed_variables.append(excluded_variable)\n",
    "            print(f\"제거된 변수: {excluded_variable} (p-value: {max_p_value:.4f})\")\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return variables\n",
    "\n",
    "# 변수 선택\n",
    "selected_variables = backward_elimination(X_train, y_train)\n",
    "\n",
    "# 최종 모델 생성\n",
    "X_train_final = sm.add_constant(X_train[selected_variables])\n",
    "final_model = sm.OLS(y_train, X_train_final).fit()\n",
    "\n",
    "# 회귀 분석 결과 출력\n",
    "print(\"최종 모델 요약 (후진 제거법 적용 후):\")\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0dad481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 릿지 회귀 모델 및 하이퍼파라미터 그리드 정의\n",
    "# ridge_model = Ridge()\n",
    "# param_grid_ridge = {\n",
    "#     'alpha': [0.0001, 0.001, 0.01 ,0.1, 1.0, 10.0, 100.0]  # alpha는 정규화 강도\n",
    "# }\n",
    "\n",
    "# # 그리드 서치 설정# 타겟 변수와 설명 변수 정의\n",
    "# df_final['Target'] = df_merged['Target']  # 타겟 변수 추가\n",
    "\n",
    "# # 데이터 분할\n",
    "# df_train, df_test = train_test_split(df_final, test_size=0.3, random_state=1234)\n",
    "\n",
    "# print('Train data size : {}'.format(df_train.shape)) \n",
    "# print('Test data size : {}'.format(df_test.shape))\n",
    "\n",
    "# # 타겟 변수와 설명 변수 정의\n",
    "# X_train = df_train.drop(columns='Target')\n",
    "# y_train = df_train['Target']\n",
    "\n",
    "# X_test = df_test.drop(columns='Target')\n",
    "# y_test = df_test['Target']\n",
    "# grid_search_ridge = GridSearchCV(estimator=ridge_model, param_grid=param_grid_ridge, scoring='neg_mean_squared_error', cv=5)\n",
    "# grid_search_ridge.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 하이퍼파라미터와 성능 평가\n",
    "# print(f\"최적의 alpha: {grid_search_ridge.best_params_['alpha']}\")\n",
    "# print(f\"최적의 MSE: {-grid_search_ridge.best_score_:.4f}\")\n",
    "\n",
    "# # 최적의 모델을 사용하여 테스트 데이터 평가\n",
    "# best_ridge_model = grid_search_ridge.best_estimator_\n",
    "# y_pred_ridge = best_ridge_model.predict(X_test)\n",
    "# mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "# print(f\"테스트 데이터 MSE (릿지 회귀): {mse_ridge:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "464a7c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 라쏘 회귀 모델 및 하이퍼파라미터 그리드 정의\n",
    "# lasso_model = Lasso()\n",
    "# param_grid_lasso = {\n",
    "#     'alpha': [0.0001, 0.001, 0.01 ,0.1, 1.0, 10.0, 100.0]  # alpha는 정규화 강도\n",
    "# }\n",
    "\n",
    "# # 그리드 서치 설정\n",
    "# grid_search_lasso = GridSearchCV(estimator=lasso_model, param_grid=param_grid_lasso, scoring='neg_mean_squared_error', cv=5)\n",
    "# grid_search_lasso.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 하이퍼파라미터와 성능 평가\n",
    "# print(f\"최적의 alpha: {grid_search_lasso.best_params_['alpha']}\")\n",
    "# print(f\"최적의 MSE: {-grid_search_lasso.best_score_:.4f}\")\n",
    "\n",
    "# # 최적의 모델을 사용하여 테스트 데이터 평가\n",
    "# best_lasso_model = grid_search_lasso.best_estimator_\n",
    "# y_pred_lasso = best_lasso_model.predict(X_test)\n",
    "# mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "# print(f\"테스트 데이터 MSE (라쏘 회귀): {mse_lasso:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f991d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 엘라스틱넷 회귀 모델 및 하이퍼파라미터 그리드 정의\n",
    "# elastic_net_model = ElasticNet()\n",
    "# param_grid_en = {\n",
    "#     'alpha': [0.0001, 0.001, 0.01 ,0.1, 1.0, 10.0, 100.0],  # alpha는 정규화 강도\n",
    "#     'l1_ratio': [0.1, 0.5, 0.9]  # l1_ratio는 L1과 L2의 비율\n",
    "# }\n",
    "\n",
    "# # 그리드 서치 설정\n",
    "# grid_search_en = GridSearchCV(estimator=elastic_net_model, param_grid=param_grid_en, scoring='neg_mean_squared_error', cv=5)\n",
    "# grid_search_en.fit(X_train, y_train)\n",
    "\n",
    "# # 최적의 하이퍼파라미터와 성능 평가\n",
    "# print(f\"최적의 alpha: {grid_search_en.best_params_['alpha']}\")\n",
    "# print(f\"최적의 l1_ratio: {grid_search_en.best_params_['l1_ratio']}\")\n",
    "# print(f\"최적의 MSE: {-grid_search_en.best_score_:.4f}\")\n",
    "\n",
    "# # 최적의 모델을 사용하여 테스트 데이터 평가\n",
    "# best_en_model = grid_search_en.best_estimator_\n",
    "# y_pred_en = best_en_model.predict(X_test)\n",
    "# mse_en = mean_squared_error(y_test, y_pred_en)\n",
    "# print(f\"테스트 데이터 MSE (엘라스틱넷 회귀): {mse_en:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba9ef9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 928.4820\n",
      "R^2 Score: 0.7475\n",
      "\n",
      "Ridge 회귀 계수:\n",
      "Lot_Num_21                       45.202713\n",
      "Lot_Num_20                       40.497986\n",
      "Lot_Num_25                       36.426804\n",
      "Lot_Num_23                       35.246716\n",
      "Lot_Num_22                       29.607187\n",
      "                                   ...    \n",
      "Wafer_Num_53                    -13.169893\n",
      "Wafer_Num_38                    -14.934110\n",
      "Wafer_Num_46                    -18.611250\n",
      "Error_message_[['Edge-Ring']]   -31.515829\n",
      "Error_message_none              -89.872233\n",
      "Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 릿지 회귀 모델 생성 및 학습\n",
    "ridge_model = Ridge(alpha=0.0001, random_state=1234)  # alpha는 정규화 강도를 조절하는 하이퍼파라미터입니다.\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R^2 Score: {r2:.4f}\")\n",
    "\n",
    "# 모델의 계수 출력\n",
    "coefficients = pd.Series(ridge_model.coef_, index=X_train.columns)\n",
    "print(\"\\nRidge 회귀 계수:\")\n",
    "print(coefficients.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09385624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라쏘 회귀 - Mean Squared Error: 928.4734\n",
      "라쏘 회귀 - R^2 Score: 0.7475\n",
      "\n",
      "라쏘 회귀 계수:\n",
      "Lot_Num_21                       45.122262\n",
      "Lot_Num_20                       40.417431\n",
      "Lot_Num_25                       36.340467\n",
      "Lot_Num_23                       35.165081\n",
      "Lot_Num_22                       29.523617\n",
      "                                   ...    \n",
      "Wafer_Num_37                    -14.395417\n",
      "Wafer_Num_38                    -14.751329\n",
      "Wafer_Num_46                    -18.432151\n",
      "Error_message_[['Edge-Ring']]   -31.450057\n",
      "Error_message_none              -89.893733\n",
      "Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 라쏘 회귀 모델 생성 및 학습\n",
    "lasso_model = Lasso(alpha=0.0001, random_state=1234)  # alpha는 정규화 강도를 조절하는 하이퍼파라미터입니다.\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(f\"라쏘 회귀 - Mean Squared Error: {mse_lasso:.4f}\")\n",
    "print(f\"라쏘 회귀 - R^2 Score: {r2_lasso:.4f}\")\n",
    "\n",
    "# 모델의 계수 출력\n",
    "coefficients_lasso = pd.Series(lasso_model.coef_, index=X_train.columns)\n",
    "print(\"\\n라쏘 회귀 계수:\")\n",
    "print(coefficients_lasso.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ce8256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "엘라스틱넷 회귀 - Mean Squared Error: 928.5204\n",
      "엘라스틱넷 회귀 - R^2 Score: 0.7475\n",
      "\n",
      "엘라스틱넷 회귀 계수:\n",
      "Lot_Num_21                       44.932231\n",
      "Lot_Num_20                       40.235775\n",
      "Lot_Num_25                       36.172222\n",
      "Lot_Num_23                       34.985498\n",
      "Lot_Num_22                       29.340111\n",
      "                                   ...    \n",
      "Wafer_Num_37                    -13.660501\n",
      "Wafer_Num_38                    -14.614699\n",
      "Wafer_Num_46                    -18.300033\n",
      "Error_message_[['Edge-Ring']]   -31.133145\n",
      "Error_message_none              -89.751460\n",
      "Length: 148, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 엘라스틱넷 회귀 모델 생성 및 학습\n",
    "elastic_net_model = ElasticNet(alpha=0.0001, l1_ratio=0.9, random_state=1234)  # alpha는 정규화 강도, l1_ratio는 L1과 L2의 비율\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_en = elastic_net_model.predict(X_test)\n",
    "\n",
    "# 성능 평가\n",
    "mse_en = mean_squared_error(y_test, y_pred_en)\n",
    "r2_en = r2_score(y_test, y_pred_en)\n",
    "\n",
    "print(f\"엘라스틱넷 회귀 - Mean Squared Error: {mse_en:.4f}\")\n",
    "print(f\"엘라스틱넷 회귀 - R^2 Score: {r2_en:.4f}\")\n",
    "\n",
    "# 모델의 계수 출력\n",
    "coefficients_en = pd.Series(elastic_net_model.coef_, index=X_train.columns)\n",
    "print(\"\\n엘라스틱넷 회귀 계수:\")\n",
    "print(coefficients_en.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d6817dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#         'max_depth': [i for i in range(1,7)],\n",
    "#         'min_samples_split': [i*10 for i in range(3,8)],\n",
    "#         'min_samples_leaf': [i*5 for i in range(2,5)]}\n",
    "\n",
    "# dt_reg = DecisionTreeRegressor()\n",
    "# grid_search = GridSearchCV(estimator=dt_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_dt_reg = grid_search.best_estimator_\n",
    "# best_params = best_dt_reg.get_params()\n",
    "# print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "171fe908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#         'n_estimators': [50, 100, 200],\n",
    "#         'max_depth': [i for i in range(1,7)],\n",
    "#         'min_samples_split': [i*10 for i in range(3,8)],\n",
    "#         'min_samples_leaf': [i*5 for i in range(2,5)]}\n",
    "\n",
    "# rf_reg = RandomForestRegressor(random_state=1234)\n",
    "# grid_search = GridSearchCV(estimator=rf_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# best_rf_reg = grid_search.best_estimator_\n",
    "# best_params = best_rf_reg.get_params()\n",
    "# print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "        'max_depth': [i for i in range(1,7)],\n",
    "        'min_samples_split': [i*10 for i in range(3,8)],\n",
    "        'min_samples_leaf': [i*5 for i in range(2,5)]}\n",
    "\n",
    "gb_reg = GradientBoostingRegressor(random_state=1234)\n",
    "grid_search = GridSearchCV(estimator=gb_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_gb_reg = grid_search.best_estimator_\n",
    "best_params = best_gb_reg.get_params()\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc98ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "        'max_depth': [i for i in range(1,7)],\n",
    "        'min_samples_split': [i*10 for i in range(3,8)],\n",
    "        'min_samples_leaf': [i*5 for i in range(2,5)]}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(random_state=1234)\n",
    "grid_search = GridSearchCV(estimator=gb_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(df_x, df_y)\n",
    "best_gb_reg = grid_search.best_estimator_\n",
    "best_params = best_gb_reg.get_params()\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2],\n",
    "        'max_depth': [i for i in range(1,7)],\n",
    "        'min_samples_split': [i*10 for i in range(3,8)],\n",
    "        'min_samples_leaf': [i*5 for i in range(2,5)]}\n",
    "\n",
    "lgb_model = lgb.LGBMRegressor(random_state=1234)\n",
    "grid_search = GridSearchCV(estimator=gb_reg, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(df_x, df_y)\n",
    "best_gb_reg = grid_search.best_estimator_\n",
    "best_params = best_gb_reg.get_params()\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결정 트리 회귀 모델 생성 및 학습\n",
    "decision_tree_model = DecisionTreeRegressor(ccp_alpha = 0.0, criterion = 'squared_error', max_depth = 6, max_features = None, \\\n",
    "                                            max_leaf_nodes = None, min_impurity_decrease = 0.0, min_samples_leaf = 10, \\\n",
    "                                            min_samples_split = 30, min_weight_fraction_leaf = 0.0, random_state = 1234, splitter = 'best')\n",
    "decision_tree_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "y_pred_dt = decision_tree_model.predict(X_test)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "print(f\"테스트 데이터 MSE (결정 트리 회귀): {mse_dt:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c97db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 중요도\n",
    "feature_importances_tree = pd.Series(decision_tree_model.feature_importances_, index=X_train.columns)\n",
    "print(\"결정 트리 피처 중요도:\")\n",
    "print(feature_importances_tree.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfab856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 포레스트 회귀 모델 생성 및 학습\n",
    "random_forest_model = RandomForestRegressor(bootstrap = True, ccp_alpha = 0.0, criterion = 'squared_error', max_depth = 6, \\\n",
    "                                            max_features = 1.0, max_leaf_nodes = None, max_samples = None, min_impurity_decrease = 0.0,\\\n",
    "                                            min_samples_leaf = 10, min_samples_split = 30, min_weight_fraction_leaf = 0.0,\\\n",
    "                                            n_estimators = 200, n_jobs = None, oob_score = False, random_state = 1234, verbose = 0, \\\n",
    "                                            warm_start = False)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "y_pred_rf = random_forest_model.predict(X_test)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "print(f\"테스트 데이터 MSE (랜덤 포레스트 회귀): {mse_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858e1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 중요도\n",
    "feature_importances_forest = pd.Series(random_forest_model.feature_importances_, index=X_train.columns)\n",
    "print(\"랜덤 포레스트 피처 중요도:\")\n",
    "print(feature_importances_forest.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d81e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래디언트 부스팅 회귀 모델 생성 및 학습\n",
    "gradient_boosting_model = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth)\n",
    "gradient_boosting_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "y_pred_gb = gradient_boosting_model.predict(X_test)\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "print(f\"테스트 데이터 MSE (그래디언트 부스팅 회귀): {mse_gb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 중요도\n",
    "feature_importances_gboost = pd.Series(gradient_boosting_model.feature_importances_, index=X_train.columns)\n",
    "print(\"그래디언트 부스팅 피처 중요도:\")\n",
    "print(feature_importances_gboost.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8508243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 회귀 모델 생성 및 학습\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, objective='reg:squarederror')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "print(f\"테스트 데이터 MSE (XGBoost 회귀): {mse_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f902bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 중요도\n",
    "feature_importances_xgb = pd.Series(xgb_model.feature_importances_, index=X_train.columns)\n",
    "print(\"XGBoost 피처 중요도:\")\n",
    "print(feature_importances_xgb.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb16314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM 회귀 모델 생성 및 학습\n",
    "lgb_model = lgb.LGBMRegressor(n_estimators=n_estimators, learning_rate=learning_rate, num_leaves=num_leaves)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "mse_lgb = mean_squared_error(y_test, y_pred_lgb)\n",
    "print(f\"테스트 데이터 MSE (LightGBM 회귀): {mse_lgb:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646066f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 중요도\n",
    "feature_importances_lgb = pd.Series(lgb_model.feature_importances_, index=X_train.columns)\n",
    "print(\"LightGBM 피처 중요도:\")\n",
    "print(feature_importances_lgb.sort_values(ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
